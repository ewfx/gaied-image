{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9eb72b3-2bb7-47bc-8a7f-4f91aa58ba4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3282995753.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 28\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"Adjustment\": [],\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ TEST API KEYS\n",
    "from PyPDF2 import PdfReader\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import torch\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "print(\"üîê Testing API Keys...\")\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyD6NgaD8zkS65XpWcx4X-6aIZdfryty_u0\"\n",
    "\n",
    "def test_gemini_api():\n",
    "    try:\n",
    "        genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        response = model.generate_content(\"Say 'Hello from Gemini!'\")\n",
    "        print(\"‚úÖ Gemini response:\", response.text.strip())\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Gemini error:\", str(e))\n",
    "\n",
    "test_gemini_api()\n",
    "\n",
    "# ‚úÖ STEP 3: CONFIGURE REQUEST TYPES\n",
    "REQUEST_TYPES = {email,\n",
    "    \"Adjustment\": [],\n",
    "    \"AU Transfer\": [],\n",
    "    \"Closing Notice\": [\"Reallocation Fees\", \"Amendment Fees\", \"Reallocation Principal\"],\n",
    "    \"Commitment Change\": [\"Cashless Roll\", \"Decrease\", \"Increase\"],\n",
    "    \"Fee Payment\": [\"Ongoing Fee\", \"Letter of Credit Fee\"],\n",
    "    \"Money Movement-Inbound\": [\"Principal\", \"Interest\", \"Principal + Interest\", \"Principal+Interest+Fee\"],\n",
    "    \"Money Movement - Outbound\": [\"Timebound\", \"Foreign Currency\"]\n",
    "}\n",
    "\n",
    "# ‚úÖ STEP 4: GENERATE SYNTHETIC DATA FIRST (EXPANDED FOR SUB-REQUESTS)\n",
    "import random\n",
    "\n",
    "synthetic_data = []\n",
    "\n",
    "money_inbound_templates = [\n",
    "    \"Effective {date}, the borrower intends to repay USD {amount} via wire transfer to Wells Fargo.\",\n",
    "    \"We will remit USD {amount} on {date}. Please credit to account ending with {account}.\",\n",
    "    \"USD {amount} will be wired to your account under SOFR on {date}. Reference ID: {ref}.\",\n",
    "    \"This is a notification of loan repayment. USD {amount} will be sent on {date} to ABA {aba}.\",\n",
    "    \"Please note the principal repayment of USD {amount} effective {date} as per SOFR terms.\"\n",
    "]\n",
    "\n",
    "for i in range(25):\n",
    "    template = random.choice(money_inbound_templates)\n",
    "    filled = template.format(\n",
    "        date=f\"March {random.randint(1,28)}, 2024\",\n",
    "        amount=f\"{random.randint(1,25)*1000000:,}\",\n",
    "        account=f\"{random.randint(1000,9999)}\",\n",
    "        aba=f\"{random.randint(100000000,999999999)}\",\n",
    "        ref=f\"CUSIP{random.randint(100000,999999)}\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Money Movement-Inbound\"})\n",
    "\n",
    "# Include other request types (already added previously, no need to repeat here)\n",
    "# Reuse same logic to generate 'synthetic_data'\n",
    "\n",
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "synthetic_df.to_csv(\"synthetic_emails.csv\", index=False)\n",
    "print(\"‚úÖ Synthetic data saved to synthetic_emails.csv\")\n",
    "\n",
    "# ‚úÖ STEP 5: LOAD DATASET AND PREP LABELS\n",
    "combined_df = pd.concat([\n",
    "    pd.read_csv(\"emails_dataset.csv\"),\n",
    "    pd.read_csv(\"synthetic_emails.csv\")\n",
    "], ignore_index=True)\n",
    "combined_df.drop_duplicates(subset=[\"email_text\"], inplace=True)\n",
    "df = combined_df\n",
    "df[\"label\"] = df[\"request_type\"].astype(\"category\").cat.codes\n",
    "main_label_mapping = dict(enumerate(df[\"request_type\"].astype(\"category\").cat.categories))\n",
    "num_labels = len(main_label_mapping)\n",
    "\n",
    "# ‚úÖ STEP 5: CONVERT TO DATASET AND TOKENIZE\n",
    "dataset = Dataset.from_pandas(df)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    tokens = tokenizer(example[\"email_text\"], padding=\"max_length\", truncation=True)\n",
    "    tokens[\"labels\"] = example[\"label\"]\n",
    "    return tokens\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "splits = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = splits[\"train\"]\n",
    "eval_dataset = splits[\"test\"]\n",
    "\n",
    "# ‚úÖ STEP 6: DEFINE MODEL\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
    "\n",
    "# ‚úÖ STEP 7: METRICS\n",
    "eval_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return eval_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# ‚úÖ STEP 8: TRAINING ARGUMENTS\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ‚úÖ STEP 9: TRAIN\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ‚úÖ STEP 10: SAVE MODEL\n",
    "model.save_pretrained(\"email_classifier_bert\")\n",
    "tokenizer.save_pretrained(\"email_classifier_bert\")\n",
    "\n",
    "# ‚úÖ STEP 11: INFERENCE FUNCTION\n",
    "def predict_email_verbose(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = outputs.logits.softmax(dim=1).detach().cpu().numpy()[0]\n",
    "    for i, p in enumerate(probs):\n",
    "        print(f\"{main_label_mapping[i]}: {round(p, 3)}\")\n",
    "    pred_index = np.argmax(probs)\n",
    "    return {\n",
    "        \"Prediction\": main_label_mapping[pred_index],\n",
    "        \"Confidence\": round(probs[pred_index], 3)\n",
    "    }\n",
    "\n",
    "# ‚úÖ STEP 12: ENSEMBLE CLASSIFIER (WITHOUT HF)\n",
    "def classify_gemini(text):\n",
    "    genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    prompt = f\"Classify this email into: {list(REQUEST_TYPES.keys())}.\\n\\nEmail:\\n{text}\\n\\nClassification:\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text.strip()\n",
    "\n",
    "def priority_override(text, predicted_label):\n",
    "    text_lower = text.lower()\n",
    "    if \"repay under sofr\" in text_lower or \"we will remit\" in text_lower or (\"aba\" in text_lower and \"usd\" in text_lower):\n",
    "        return \"Money Movement-Inbound\"\n",
    "    return predicted_label\n",
    "\n",
    "def ensemble_classify(text):\n",
    "    base = predict_email_verbose(text)\n",
    "    base_prediction = base[\"Prediction\"]\n",
    "    base_conf = base[\"Confidence\"]\n",
    "\n",
    "    try:\n",
    "        gemini_pred = classify_gemini(text)\n",
    "    except:\n",
    "        gemini_pred = None\n",
    "\n",
    "    votes = [base_prediction]\n",
    "    if gemini_pred:\n",
    "        votes.append(gemini_pred)\n",
    "\n",
    "    vote_counts = {label: votes.count(label) for label in set(votes)}\n",
    "    majority = max(vote_counts, key=vote_counts.get)\n",
    "\n",
    "    # üîê Confidence rule: if model is too uncertain, prefer Gemini\n",
    "    if base_conf < 0.5 and gemini_pred:\n",
    "        final = gemini_pred\n",
    "        print(\"‚ö†Ô∏è Low confidence fallback to Gemini\")\n",
    "    else:\n",
    "        final = majority\n",
    "\n",
    "    # ‚úÖ Apply keyword-based override\n",
    "    final = priority_override(text, final)\n",
    "\n",
    "    return {\n",
    "        \"Final Classification\": final,\n",
    "        \"Votes\": votes,\n",
    "        \"Confidence\": base_conf\n",
    "    }\n",
    "\n",
    "# ‚úÖ STEP 13: PDF TEXT EXTRACTION\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text.strip()\n",
    "\n",
    "# ‚úÖ STEP 14: SYNTHETIC DATA GENERATION\n",
    "import random\n",
    "\n",
    "synthetic_data = []\n",
    "\n",
    "money_inbound_templates = [\n",
    "    \"Effective {date}, the borrower intends to repay USD {amount} via wire transfer to Wells Fargo.\",\n",
    "    \"We will remit USD {amount} on {date}. Please credit to account ending with {account}.\",\n",
    "    \"USD {amount} will be wired to your account under SOFR on {date}. Reference ID: {ref}.\",\n",
    "    \"This is a notification of loan repayment. USD {amount} will be sent on {date} to ABA {aba}.\",\n",
    "    \"Please note the principal repayment of USD {amount} effective {date} as per SOFR terms.\"\n",
    "]\n",
    "\n",
    "for i in range(10):\n",
    "    template = random.choice(money_inbound_templates)\n",
    "    filled = template.format(\n",
    "        date=f\"March {random.randint(1,28)}, 2024\",\n",
    "        amount=f\"{random.randint(1,25)*1000000:,}\",\n",
    "        account=f\"{random.randint(1000,9999)}\",\n",
    "        aba=f\"{random.randint(100000000,999999999)}\",\n",
    "        ref=f\"CUSIP{random.randint(100000,999999)}\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Money Movement-Inbound\"})\n",
    "\n",
    "# Add synthetic samples for other request types\n",
    "adjustment_templates = [\n",
    "    \"We have identified a discrepancy and made an adjustment of USD {amount} to your account.\",\n",
    "    \"An adjustment has been processed due to a previous miscalculation on {date}.\",\n",
    "    \"Adjustment entry of USD {amount} recorded for interest correction.\",\n",
    "    \"System adjustment performed to rectify overcharge of USD {amount} on {date}.\",\n",
    "    \"Reconciliation complete. USD {amount} has been credited back.\"\n",
    "]\n",
    "for i in range(10):\n",
    "    filled = random.choice(adjustment_templates).format(\n",
    "        amount=f\"{random.randint(1,5)*10000:,}\",\n",
    "        date=f\"April {random.randint(1,28)}, 2024\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Adjustment\"})\n",
    "\n",
    "au_transfer_templates = [\n",
    "    \"Please initiate AU transfer of USD {amount} to account {account}.\",\n",
    "    \"AU transfer of USD {amount} has been approved for release.\",\n",
    "    \"The AU transfer request for USD {amount} is scheduled for {date}.\",\n",
    "    \"Transfer funds under AU regulation to the designated beneficiary. Amount: USD {amount}.\",\n",
    "    \"Initiate AU transfer referencing transaction ID {ref}.\"\n",
    "]\n",
    "for i in range(10):\n",
    "    filled = random.choice(au_transfer_templates).format(\n",
    "        amount=f\"{random.randint(1,10)*100000:,}\",\n",
    "        account=f\"{random.randint(10000000,99999999)}\",\n",
    "        date=f\"May {random.randint(1,28)}, 2024\",\n",
    "        ref=f\"AU-{random.randint(10000,99999)}\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"AU Transfer\"})\n",
    "\n",
    "closing_notice_templates = [\n",
    "    \"This notice serves as confirmation of the facility closing effective {date}.\",\n",
    "    \"Facility has been closed. Final payment of USD {amount} received.\",\n",
    "    \"Loan closure completed on {date}. All dues cleared.\",\n",
    "    \"As of {date}, the credit line stands closed per agreement.\",\n",
    "    \"Final reallocation completed. Facility closed with ref ID {ref}.\"\n",
    "]\n",
    "for i in range(10):\n",
    "    filled = random.choice(closing_notice_templates).format(\n",
    "        date=f\"June {random.randint(1,28)}, 2024\",\n",
    "        amount=f\"{random.randint(5,20)*100000:,}\",\n",
    "        ref=f\"CL-{random.randint(1000,9999)}\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Closing Notice\"})\n",
    "\n",
    "commitment_change_templates = [\n",
    "    \"We request a decrease in commitment amount by USD {amount} effective {date}.\",\n",
    "    \"An increase of USD {amount} has been approved for your credit facility.\",\n",
    "    \"Cashless roll of existing commitment into new term commencing {date}.\",\n",
    "    \"Commitment reduction of USD {amount} is scheduled for {date}.\",\n",
    "    \"Please reflect updated commitment amount per attached schedule.\"\n",
    "]\n",
    "for i in range(10):\n",
    "    filled = random.choice(commitment_change_templates).format(\n",
    "        amount=f\"{random.randint(1,15)*100000:,}\",\n",
    "        date=f\"July {random.randint(1,28)}, 2024\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Commitment Change\"})\n",
    "\n",
    "fee_payment_templates = [\n",
    "    \"Ongoing fee of USD {amount} due on {date}.\",\n",
    "    \"Please process payment of USD {amount} for letter of credit fee.\",\n",
    "    \"Fee invoice attached for USD {amount}.\",\n",
    "    \"USD {amount} to be charged for maintenance fee.\",\n",
    "    \"Scheduled fee of USD {amount} processed on {date}.\"\n",
    "]\n",
    "for i in range(10):\n",
    "    filled = random.choice(fee_payment_templates).format(\n",
    "        amount=f\"{random.randint(1,10)*10000:,}\",\n",
    "        date=f\"August {random.randint(1,28)}, 2024\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Fee Payment\"})\n",
    "\n",
    "money_outbound_templates = [\n",
    "    \"Please initiate outbound payment of USD {amount} to foreign beneficiary.\",\n",
    "    \"Outbound wire of USD {amount} scheduled for {date}.\",\n",
    "    \"USD {amount} transfer initiated to HSBC London, reference {ref}.\",\n",
    "    \"FX payment outbound initiated, value date {date}.\",\n",
    "    \"Foreign currency outbound transfer completed: USD {amount}.\"\n",
    "]\n",
    "for i in range(10):\n",
    "    filled = random.choice(money_outbound_templates).format(\n",
    "        amount=f\"{random.randint(1,25)*100000:,}\",\n",
    "        date=f\"September {random.randint(1,28)}, 2024\",\n",
    "        ref=f\"OUT-{random.randint(1000,9999)}\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Money Movement - Outbound\"})\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "synthetic_df.to_csv(\"synthetic_emails.csv\", index=False)\n",
    "print(\"‚úÖ Synthetic data saved to synthetic_emails.csv\")\n",
    "\n",
    "# ‚úÖ STEP 15: SUB-REQUEST CLASSIFICATION\n",
    "sub_request_mapping = {k: v for k, v in REQUEST_TYPES.items() if v}\n",
    "\n",
    "def classify_sub_request(text, main_class):\n",
    "    sub_options = sub_request_mapping.get(main_class, [])\n",
    "    if not sub_options:\n",
    "        return None\n",
    "    prompt = f\"\"\"Classify this email into one of the following sub-request types: {sub_options}.\n",
    "\n",
    "Email:\n",
    "{text}\n",
    "\n",
    "Sub-Request Classification:\"\"\"\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Sub-request classification failed:\", e)\n",
    "        return None\n",
    "\n",
    "# ‚úÖ STEP 16: TEST CLASSIFICATION\n",
    "pdf_text = extract_text_from_pdf(\"sample1.pdf\")\n",
    "result = ensemble_classify(pdf_text)\n",
    "print(result)\n",
    "\n",
    "# Optional: Sub-request classification if needed\n",
    "sub = classify_sub_request(pdf_text, result['Final Classification'])\n",
    "if sub:\n",
    "    print(f\"üîç Sub-Request Type: {sub}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672cb0a-03c5-4b6f-bf0b-87cca64cb5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from transformers import BertForSequenceClassification, BertTokenizerFast\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load your trained model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(\"email_classifier_bert\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"email_classifier_bert\")\n",
    "\n",
    "# Rebuild label mapping from your original dataset\n",
    "df = pd.read_csv(\"emails_dataset.csv\")  # Make sure this is the dataset you trained on\n",
    "df[\"label\"] = df[\"request_type\"].astype(\"category\").cat.codes\n",
    "main_label_mapping = dict(enumerate(df[\"request_type\"].astype(\"category\").cat.categories))\n",
    "\n",
    "# Create id2label and label2id\n",
    "id2label = {i: label for i, label in main_label_mapping.items()}\n",
    "label2id = {label: i for i, label in main_label_mapping.items()}\n",
    "\n",
    "# Inject into config\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id\n",
    "\n",
    "# Save to new folder to avoid Windows file-lock issue\n",
    "new_model_dir = \"email_classifier_bert_v2\"\n",
    "model.save_pretrained(new_model_dir, safe_serialization=False)\n",
    "tokenizer.save_pretrained(new_model_dir)\n",
    "\n",
    "# Save external label mapping\n",
    "with open(\"label_mapping.json\", \"w\") as f:\n",
    "    json.dump({str(k): v for k, v in id2label.items()}, f)\n",
    "\n",
    "print(f\"‚úÖ Model and label mapping saved to {new_model_dir}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d7467-48d9-4871-86e9-cea21558d00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
