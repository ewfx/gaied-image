{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9eb72b3-2bb7-47bc-8a7f-4f91aa58ba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aract\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aract\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "üîê Testing API Keys...\n",
      "‚úÖ Gemini response: Hello from Gemini!\n",
      "‚úÖ Synthetic data saved to synthetic_emails.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33086cc3f6b467ca2aba0d8f9cd76d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/173 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\aract\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\aract\\AppData\\Local\\Temp\\ipykernel_42168\\3848967875.py:118: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 01:06, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.565956</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.227542</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.770016</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.434334</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.390551</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289806</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Synthetic data saved to synthetic_emails.csv\n",
      "AU Transfer: 0.017999999225139618\n",
      "Adjustment: 0.026000000536441803\n",
      "Closing Notice: 0.03099999949336052\n",
      "Commitment Change: 0.06199999898672104\n",
      "Fee Payment: 0.13199999928474426\n",
      "Money Movement - Outbound: 0.07900000363588333\n",
      "Money Movement-Inbound: 0.6520000100135803\n",
      "{'Final Classification': 'Money Movement-Inbound', 'Votes': ['Money Movement-Inbound', 'Money Movement - Outbound'], 'Confidence': 0.652}\n",
      "üîç Sub-Request Type: Principal + Interest\n",
      "\n",
      "The email clearly shows a principal repayment (reduction from USD 45,000,000.00 to USD 25,000,000.00) and a separate interest payment of USD 1,411,764.71.  There's no mention of fees.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ TEST API KEYS\n",
    "from PyPDF2 import PdfReader\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import torch\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "print(\"üîê Testing API Keys...\")\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyD6NgaD8zkS65XpWcx4X-6aIZdfryty_u0\"\n",
    "\n",
    "def test_gemini_api():\n",
    "    try:\n",
    "        genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        response = model.generate_content(\"Say 'Hello from Gemini!'\")\n",
    "        print(\"‚úÖ Gemini response:\", response.text.strip())\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Gemini error:\", str(e))\n",
    "\n",
    "test_gemini_api()\n",
    "\n",
    "# ‚úÖ STEP 3: CONFIGURE REQUEST TYPES\n",
    "REQUEST_TYPES = {\n",
    "    \"Adjustment\": [],\n",
    "    \"AU Transfer\": [],\n",
    "    \"Closing Notice\": [\"Reallocation Fees\", \"Amendment Fees\", \"Reallocation Principal\"],\n",
    "    \"Commitment Change\": [\"Cashless Roll\", \"Decrease\", \"Increase\"],\n",
    "    \"Fee Payment\": [\"Ongoing Fee\", \"Letter of Credit Fee\"],\n",
    "    \"Money Movement-Inbound\": [\"Principal\", \"Interest\", \"Principal + Interest\", \"Principal+Interest+Fee\"],\n",
    "    \"Money Movement - Outbound\": [\"Timebound\", \"Foreign Currency\"]\n",
    "}\n",
    "\n",
    "# ‚úÖ STEP 4: GENERATE SYNTHETIC DATA FIRST (EXPANDED FOR SUB-REQUESTS)\n",
    "import random\n",
    "\n",
    "synthetic_data = []\n",
    "\n",
    "money_inbound_templates = [\n",
    "    \"Effective {date}, the borrower intends to repay USD {amount} via wire transfer to Wells Fargo.\",\n",
    "    \"We will remit USD {amount} on {date}. Please credit to account ending with {account}.\",\n",
    "    \"USD {amount} will be wired to your account under SOFR on {date}. Reference ID: {ref}.\",\n",
    "    \"This is a notification of loan repayment. USD {amount} will be sent on {date} to ABA {aba}.\",\n",
    "    \"Please note the principal repayment of USD {amount} effective {date} as per SOFR terms.\"\n",
    "]\n",
    "\n",
    "for i in range(25):\n",
    "    template = random.choice(money_inbound_templates)\n",
    "    filled = template.format(\n",
    "        date=f\"March {random.randint(1,28)}, 2024\",\n",
    "        amount=f\"{random.randint(1,25)*1000000:,}\",\n",
    "        account=f\"{random.randint(1000,9999)}\",\n",
    "        aba=f\"{random.randint(100000000,999999999)}\",\n",
    "        ref=f\"CUSIP{random.randint(100000,999999)}\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Money Movement-Inbound\"})\n",
    "\n",
    "# Include other request types (already added previously, no need to repeat here)\n",
    "# Reuse same logic to generate 'synthetic_data'\n",
    "\n",
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "synthetic_df.to_csv(\"synthetic_emails.csv\", index=False)\n",
    "print(\"‚úÖ Synthetic data saved to synthetic_emails.csv\")\n",
    "\n",
    "# ‚úÖ STEP 5: LOAD DATASET AND PREP LABELS\n",
    "combined_df = pd.concat([\n",
    "    pd.read_csv(\"emails_dataset.csv\"),\n",
    "    pd.read_csv(\"synthetic_emails.csv\")\n",
    "], ignore_index=True)\n",
    "combined_df.drop_duplicates(subset=[\"email_text\"], inplace=True)\n",
    "df = combined_df\n",
    "df[\"label\"] = df[\"request_type\"].astype(\"category\").cat.codes\n",
    "main_label_mapping = dict(enumerate(df[\"request_type\"].astype(\"category\").cat.categories))\n",
    "num_labels = len(main_label_mapping)\n",
    "\n",
    "# ‚úÖ STEP 5: CONVERT TO DATASET AND TOKENIZE\n",
    "dataset = Dataset.from_pandas(df)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    tokens = tokenizer(example[\"email_text\"], padding=\"max_length\", truncation=True)\n",
    "    tokens[\"labels\"] = example[\"label\"]\n",
    "    return tokens\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "splits = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = splits[\"train\"]\n",
    "eval_dataset = splits[\"test\"]\n",
    "\n",
    "# ‚úÖ STEP 6: DEFINE MODEL\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
    "\n",
    "# ‚úÖ STEP 7: METRICS\n",
    "eval_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return eval_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# ‚úÖ STEP 8: TRAINING ARGUMENTS\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ‚úÖ STEP 9: TRAIN\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ‚úÖ STEP 10: SAVE MODEL\n",
    "model.save_pretrained(\"email_classifier_bert\")\n",
    "tokenizer.save_pretrained(\"email_classifier_bert\")\n",
    "\n",
    "# ‚úÖ STEP 11: INFERENCE FUNCTION\n",
    "def predict_email_verbose(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = outputs.logits.softmax(dim=1).detach().cpu().numpy()[0]\n",
    "    for i, p in enumerate(probs):\n",
    "        print(f\"{main_label_mapping[i]}: {round(p, 3)}\")\n",
    "    pred_index = np.argmax(probs)\n",
    "    return {\n",
    "        \"Prediction\": main_label_mapping[pred_index],\n",
    "        \"Confidence\": round(probs[pred_index], 3)\n",
    "    }\n",
    "\n",
    "# ‚úÖ STEP 12: ENSEMBLE CLASSIFIER (WITHOUT HF)\n",
    "def classify_gemini(text):\n",
    "    genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    prompt = f\"Classify this email into: {list(REQUEST_TYPES.keys())}.\\n\\nEmail:\\n{text}\\n\\nClassification:\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text.strip()\n",
    "\n",
    "def priority_override(text, predicted_label):\n",
    "    text_lower = text.lower()\n",
    "    if \"repay under sofr\" in text_lower or \"we will remit\" in text_lower or (\"aba\" in text_lower and \"usd\" in text_lower):\n",
    "        return \"Money Movement-Inbound\"\n",
    "    return predicted_label\n",
    "\n",
    "def ensemble_classify(text):\n",
    "    base = predict_email_verbose(text)\n",
    "    base_prediction = base[\"Prediction\"]\n",
    "    base_conf = base[\"Confidence\"]\n",
    "\n",
    "    try:\n",
    "        gemini_pred = classify_gemini(text)\n",
    "    except:\n",
    "        gemini_pred = None\n",
    "\n",
    "    votes = [base_prediction]\n",
    "    if gemini_pred:\n",
    "        votes.append(gemini_pred)\n",
    "\n",
    "    vote_counts = {label: votes.count(label) for label in set(votes)}\n",
    "    majority = max(vote_counts, key=vote_counts.get)\n",
    "\n",
    "    # üîê Confidence rule: if model is too uncertain, prefer Gemini\n",
    "    if base_conf < 0.5 and gemini_pred:\n",
    "        final = gemini_pred\n",
    "        print(\"‚ö†Ô∏è Low confidence fallback to Gemini\")\n",
    "    else:\n",
    "        final = majority\n",
    "\n",
    "    # ‚úÖ Apply keyword-based override\n",
    "    final = priority_override(text, final)\n",
    "\n",
    "    return {\n",
    "        \"Final Classification\": final,\n",
    "        \"Votes\": votes,\n",
    "        \"Confidence\": base_conf\n",
    "    }\n",
    "\n",
    "# ‚úÖ STEP 13: PDF TEXT EXTRACTION\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text.strip()\n",
    "\n",
    "# ‚úÖ STEP 14: SYNTHETIC DATA GENERATION\n",
    "import random\n",
    "\n",
    "synthetic_data = []\n",
    "\n",
    "money_inbound_templates = [\n",
    "    \"Effective {date}, the borrower intends to repay USD {amount} via wire transfer to Wells Fargo.\",\n",
    "    \"We will remit USD {amount} on {date}. Please credit to account ending with {account}.\",\n",
    "    \"USD {amount} will be wired to your account under SOFR on {date}. Reference ID: {ref}.\",\n",
    "    \"This is a notification of loan repayment. USD {amount} will be sent on {date} to ABA {aba}.\",\n",
    "    \"Please note the principal repayment of USD {amount} effective {date} as per SOFR terms.\"\n",
    "]\n",
    "\n",
    "for i in range(10):\n",
    "    template = random.choice(money_inbound_templates)\n",
    "    filled = template.format(\n",
    "        date=f\"March {random.randint(1,28)}, 2024\",\n",
    "        amount=f\"{random.randint(1,25)*1000000:,}\",\n",
    "        account=f\"{random.randint(1000,9999)}\",\n",
    "        aba=f\"{random.randint(100000000,999999999)}\",\n",
    "        ref=f\"CUSIP{random.randint(100000,999999)}\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Money Movement-Inbound\"})\n",
    "\n",
    "# Add synthetic samples for other request types\n",
    "adjustment_templates = [\n",
    "    \"We have identified a discrepancy and made an adjustment of USD {amount} to your account.\",\n",
    "    \"An adjustment has been processed due to a previous miscalculation on {date}.\",\n",
    "    \"Adjustment entry of USD {amount} recorded for interest correction.\",\n",
    "    \"System adjustment performed to rectify overcharge of USD {amount} on {date}.\",\n",
    "    \"Reconciliation complete. USD {amount} has been credited back.\"\n",
    "]\n",
    "for i in range(10):\n",
    "    filled = random.choice(adjustment_templates).format(\n",
    "        amount=f\"{random.randint(1,5)*10000:,}\",\n",
    "        date=f\"April {random.randint(1,28)}, 2024\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Adjustment\"})\n",
    "\n",
    "au_transfer_templates = [\n",
    "    \"Please initiate AU transfer of USD {amount} to account {account}.\",\n",
    "    \"AU transfer of USD {amount} has been approved for release.\",\n",
    "    \"The AU transfer request for USD {amount} is scheduled for {date}.\",\n",
    "    \"Transfer funds under AU regulation to the designated beneficiary. Amount: USD {amount}.\",\n",
    "    \"Initiate AU transfer referencing transaction ID {ref}.\"\n",
    "]\n",
    "for i in range(10):\n",
    "    filled = random.choice(au_transfer_templates).format(\n",
    "        amount=f\"{random.randint(1,10)*100000:,}\",\n",
    "        account=f\"{random.randint(10000000,99999999)}\",\n",
    "        date=f\"May {random.randint(1,28)}, 2024\",\n",
    "        ref=f\"AU-{random.randint(10000,99999)}\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"AU Transfer\"})\n",
    "\n",
    "closing_notice_templates = [\n",
    "    \"This notice serves as confirmation of the facility closing effective {date}.\",\n",
    "    \"Facility has been closed. Final payment of USD {amount} received.\",\n",
    "    \"Loan closure completed on {date}. All dues cleared.\",\n",
    "    \"As of {date}, the credit line stands closed per agreement.\",\n",
    "    \"Final reallocation completed. Facility closed with ref ID {ref}.\"\n",
    "]\n",
    "for i in range(10):\n",
    "    filled = random.choice(closing_notice_templates).format(\n",
    "        date=f\"June {random.randint(1,28)}, 2024\",\n",
    "        amount=f\"{random.randint(5,20)*100000:,}\",\n",
    "        ref=f\"CL-{random.randint(1000,9999)}\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Closing Notice\"})\n",
    "\n",
    "commitment_change_templates = [\n",
    "    \"We request a decrease in commitment amount by USD {amount} effective {date}.\",\n",
    "    \"An increase of USD {amount} has been approved for your credit facility.\",\n",
    "    \"Cashless roll of existing commitment into new term commencing {date}.\",\n",
    "    \"Commitment reduction of USD {amount} is scheduled for {date}.\",\n",
    "    \"Please reflect updated commitment amount per attached schedule.\"\n",
    "]\n",
    "for i in range(10):\n",
    "    filled = random.choice(commitment_change_templates).format(\n",
    "        amount=f\"{random.randint(1,15)*100000:,}\",\n",
    "        date=f\"July {random.randint(1,28)}, 2024\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Commitment Change\"})\n",
    "\n",
    "fee_payment_templates = [\n",
    "    \"Ongoing fee of USD {amount} due on {date}.\",\n",
    "    \"Please process payment of USD {amount} for letter of credit fee.\",\n",
    "    \"Fee invoice attached for USD {amount}.\",\n",
    "    \"USD {amount} to be charged for maintenance fee.\",\n",
    "    \"Scheduled fee of USD {amount} processed on {date}.\"\n",
    "]\n",
    "for i in range(10):\n",
    "    filled = random.choice(fee_payment_templates).format(\n",
    "        amount=f\"{random.randint(1,10)*10000:,}\",\n",
    "        date=f\"August {random.randint(1,28)}, 2024\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Fee Payment\"})\n",
    "\n",
    "money_outbound_templates = [\n",
    "    \"Please initiate outbound payment of USD {amount} to foreign beneficiary.\",\n",
    "    \"Outbound wire of USD {amount} scheduled for {date}.\",\n",
    "    \"USD {amount} transfer initiated to HSBC London, reference {ref}.\",\n",
    "    \"FX payment outbound initiated, value date {date}.\",\n",
    "    \"Foreign currency outbound transfer completed: USD {amount}.\"\n",
    "]\n",
    "for i in range(10):\n",
    "    filled = random.choice(money_outbound_templates).format(\n",
    "        amount=f\"{random.randint(1,25)*100000:,}\",\n",
    "        date=f\"September {random.randint(1,28)}, 2024\",\n",
    "        ref=f\"OUT-{random.randint(1000,9999)}\"\n",
    "    )\n",
    "    synthetic_data.append({\"email_text\": filled, \"request_type\": \"Money Movement - Outbound\"})\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "synthetic_df.to_csv(\"synthetic_emails.csv\", index=False)\n",
    "print(\"‚úÖ Synthetic data saved to synthetic_emails.csv\")\n",
    "\n",
    "# ‚úÖ STEP 15: SUB-REQUEST CLASSIFICATION\n",
    "sub_request_mapping = {k: v for k, v in REQUEST_TYPES.items() if v}\n",
    "\n",
    "def classify_sub_request(text, main_class):\n",
    "    sub_options = sub_request_mapping.get(main_class, [])\n",
    "    if not sub_options:\n",
    "        return None\n",
    "    prompt = f\"\"\"Classify this email into one of the following sub-request types: {sub_options}.\n",
    "\n",
    "Email:\n",
    "{text}\n",
    "\n",
    "Sub-Request Classification:\"\"\"\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Sub-request classification failed:\", e)\n",
    "        return None\n",
    "\n",
    "# ‚úÖ STEP 16: TEST CLASSIFICATION\n",
    "pdf_text = extract_text_from_pdf(\"sample1.pdf\")\n",
    "result = ensemble_classify(pdf_text)\n",
    "print(result)\n",
    "\n",
    "# Optional: Sub-request classification if needed\n",
    "sub = classify_sub_request(pdf_text, result['Final Classification'])\n",
    "if sub:\n",
    "    print(f\"üîç Sub-Request Type: {sub}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e65b67-daad-4ece-bb96-c70885e6aac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
